%!TEX root = ../memoria.tex

\chapter{Diseño de la solución}

\section{Metodología}



Para desarrollar la plataforma y cumplir con los objetivos planteados en \ref{sec:ObjetivoPrim}, se separó el proyecto utilizando un plan de trabajo que puede resumirse en las siguientes etapas:

\begin{itemize}
\item Analizar algoritmos de reconocimiento acústico para implementar uno de ellos en la plataforma de fiscalización radial, y establecer su configuración según los requerimientos del sistema.

\item Diseñar y desarrollar la plataforma, testeado su funcionamiento con una única radio online, y comprobar que ésta detecta las canciones del repertorio de prueba.

\item ampliar el alcance de la plataforma para que sea capaz de reconocer canciones de manera simultánea, fiscalizando paralelamente en diversas radioemisoras.
\end{itemize}

\section{Selección de herramientas de desarrollo}

En base a la investigación realizada en el apartado \ref{sec:APIS} se establecieron \NumElemTablaComparativaAPIS{} aspectos para comparar los sistemas analizados, y determinar así, cual se ajusta mejor a los requerimientos del proyecto. Por ejemplo, una de las exigencias mas relevantes de la plataforma, según los objetivos secundarios planteados en \ref{sec:ObjetivosSec}, es contar con un base de datos propia que contenga todo el repertorio nacional, incluyendo además, las obras realizadas por artistas independientes, con tal de mantener toda esta información de manera local, ya sea para evitar desfases de tiempo, o cualquier otro tipo de inconvenientes, a la hora de ingresar nuevas canciones al sistema.

En la tabla \ref{tab:} se señalan las características fundamentales de cada sistema. De esta colección de herramientas, se ha optado por implementar Dejavu Project, puesto que es la única que permite trabajar con los fingerprints de forma local, al permitir crear una base de datos propia. De esta forma, el tiempo de búsqueda de coincidencias entre canciones se reduce en comparación a los otros sistemas, si se considera que estos últimos requieren realizar solicitudes a fuentes externas, que no necesariamente estarán actualizadas con los últimos estrenos musicales del país.

\begin{table}[]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{lllll}
Elemento             & Dejavu              & bmoquist/ Shazam & bfirsh/ python-echoprint & Music Identification based on Hashed Chroma Features \\
Lenguaje             & Python              & Python           & Python                   & c++                                                  \\
Base de datos        & Local               &                  & Lista en el programa     &                                                      \\
Entrada de datos     & Archivo y micrófono &                  & Lista                    & chroma files of the songs                            \\
Última actualización & Abr-15              & Ene-14           & Nov-12                   & Jul-13                                               \\
Sistema              & Unix-Fedora         &                  &                          &                                                     
\end{tabular}
\end{table}



\subsection{Descripción de Dejavu Project}


Como se ha señalado en secciones anteriores, el proyecto Dejavu es un sistema open-source desarrollado en Python, que basa su implementación en fingerprints. Sin embargo, antes de abordar su funcionamiento y especificaciones, en necesario detallar la forma en que la música o señales de audio en nuestro entorno, son transformadas para ser almacenadas en un sistema computacional.

\bigskip

El primer concepto a interiorizar es la aplicación de la Transformada Rápida de Fourier (FFT de sus siglas en inglés: Fast Fourier transform) para el procesamiento digital de señales. Esto debido a que la música es codificada digitalmente como una larga lista numérica. En el caso de un archivo .wav la cantidad de números por canal es del orden de 44100 por segundo, donde los canales corresponden a la secuencia de muestras que un parlante de música puede tocar. Los más habituales son estéreo (2 canales) o mono (un canal). Por tanto, si se contara con una canción promedio de 3 minutos 30 segundos, la cantidad de muestras alcanzaría los:

\begin{equation*}
210 [s]* 44100[muestras/s]*2[canales] = 18.522.000
\end{equation*}

Por su parte, el valor 44100 proviene del teorema de muestreo de Nyquist-Shannon, pero debido al alcance de esta memoria, abordar minuciosamente su descripción no es requerido para comprender el funcionamiento de Dejavu. Basta con señalar que este teorema matemático establece que existe un límite en la frecuencia máxima que es posible capturar con precisión durante la grabación de las señales de audio, y esta frecuencia indica que tan rápido muestreamos la señal, además de establecer que para asegurarse de tomar las muestras necesarias, es requerido aumentar al doble la frecuencia máxima. 

\bigskip

Considerando que el ser humano es incapaz de oír frecuencias por sobre los 20.000 [Hz], la norma establece que un límite de frecuencia máximo es 22.500 [Hz], por lo que utilizando el teorema de Nyquist-Shannon, es posible obtener el valor de las 44.100 muestras por segundo:

\begin{equation*}
Muestras por segundo = Frecuencia alta * 2 = 22500*2 = 44100.
\end{equation*}

Cabe destacar que en el caso de los archivos .mp3, este formato comprime estos números con la finalidad de ahorrar espacio en el disco.

\bigskip

Una vez se aplica la transforma rápida de Fourier a este conjunto de muestras, es posible generar uno de los elementos más importantes del tratamiento del audio, el espectrograma, una representación visual en dos dimensiones de la amplitud de la señal en función del tiempo y la frecuencia. Como es posible observar de la figura XX, al aplicar la FFT al conjunto de muestras, y unirlas en una sola matriz, se desprende la amplitud de la señal a una frecuencia particular, donde el color XXXX corresponde a amplitudes mayores, en oposición al verde, de amplitudes bajas. Vale decir, si se grabara la señal en un solo tono, el espectrograma creado se apreciaría como una línea recta horizontal en la frecuencia de dicho tono.

\bigskip
[]
Figura x: Espectrograma de los primero xx segundos de la canción xx donde la variable dependiente es la frecuencia, en función del tiempo.
\bigskip

Ahora, si bien cabe esperar que este espectrograma sea único para cada canción o audio, se debe tener en consideración que cualquier tipo de ruido que afecte las muestras de grabaciones en el ambiente donde se reproduce la música, provocará que la representación matricial por espectrogramas varíe una infinidad de veces, dependiendo del tipo de ruidos externos que se filtren en la grabación. Por tanto, para los algoritmos de reconocimiento acústico, es necesario encontrar la forma de identificar huellas únicas para cada canción, independiente del ruido que exista en los archivos de audio.

\bigskip

Una forma de hacerlo, es centrándose en las amplitudes más grandes de una canción, pues debido a sus altos valores, no son afectados por posibles ruidos que pueda contener el archivo de entrada. De esta forma, se definen peaks de audio, correspondientes al par de variables tiempo y frecuencia, que aluden a alguna amplitud cuyo valor es el más alto dentro de un vecindario de muestras, de tal forma que es posible discretizar la señal de audio en valores enteros, a partir de las amplitudes más grandes.

\bigskip

Para lograr lo anterior, Dejavu utiliza las herramientas de la biblioteca scipy para tratar el audio de entrada e identificar los máximos locales, tal como lo señala la imagen XXXX. De este modo, se extrae toda aquella información del espectrograma que represente amplitudes altas, por lo que, para cierto margen, el ruido de un archivo ya no influye en el algoritmo.


\bigskip
[XXXXX: imagne de peaks de auido]
\bigskip


No obstante, es posible que más de algún par discreto de [tiempo, frecuencia] de alta amplitud en una canción, coincida con pares provenientes de otras canciones, por lo que es necesario volver a tratar la información obtenida. En base a esto, surge otro concepto relevante del procesamiento de música, los fingerprints, o huella digital acústica. Ésta se define como el resumen generado a partir de una señal de audio, que contempla la utilización de una función hash, para crear, a partir de una entrada, una salida alfanumérica que representa la información que le fue dada inicialmente. Por lo tanto, los datos de entrada generan una cadena que solo pueden crearse con esos mismos datos.

\bigskip

Específicamente, la información resumida que contempla un fingerprint corresponde una combinación entre el valor de la frecuencia en un peak del audio, y la diferencia en tiempo, entre algún peak aledaño. Específicamente, Dejavu …[revisar código fuente]. De tal forma que al combinar estos peaks en función del tiempo que los separa, es posible identificar elementos en el archivo que son únicos para cada canción.

\bigskip
[img peak con rayitas]
\bigskip

Una vez comprendido los conceptos básicos que permiten caracterizar a cada una de las canciones, creando perfiles únicos para su identificación, es posible abordar el funcionamiento de Dejavu. En primer lugar, se debe contar con un sistema que permita almacenar los diversos fingerprints en una base de datos, puesto que ésta será utilizada para comparar sus registros, con el extracto de canción que se desea reconocer.

\bigskip

La base de datos utilizada con Dejavu es MySQL, cuyo esquema contiene solo dos tablas, fingerprints y songs, con una clave foránea "song\_id" que las relaciona. (AUTOINCREMENTAL? Revisar code)


\bigskip
[Contenido tabla finger][Contenido tabla songs]
\bigskip


Teniendo en consideración que se crean muchos fingerprints por canción, el campo hash es un binary(10) con tal de reducir el espacio en la base de datos.

\subsubsection{Análisis de funcionalidad}
Una vez escogido el algoritmo de reconocimiento acústico, se procede a realizar pruebas a su funcionamiento, para determinar el comportamiento frente a diversos escenarios que requieren un rendimiento adecuado por parte del programa, de modo de identificar correctamente las canciones.

De esta forma, para evaluar el rendimiento de Dejavu, se han escogido 2 circunstancias, que podrían provocar mal funcionamiento del algoritmo. Asimismo, tomando en consideración los atributos del programa mencionados en la sección anterior, se determinará su comportamiento, analizando variables como tiempos de creación de fingerprints y tamaño de la base de datos, además de tiempo de respuesta, aciertos y CONFIDENCIA de las salidas del algoritmo, para determinar la mejor configuración del mismo.

Cabe mencionar, que las características del equipo utilizado para realizar las pruebas mencionadas, se detallan en \ref{sec:CaracDelEquipo}.

\paragraph{Tiempo de creación de fingerprints}
Utilizando la configuración de Dejavu por defecto, se han creado 6 bases de datos, diferenciando cada uno de ellas en la cantidad de canciones, comenzando desde 10 obras musicales hasta 250, con tal de estudiar el tiempo transcurrido para realizar los fingerprints correspondientes.

En la tabla \ref{tab:BDD10_250} se comparan las bases de datos creadas, observándose su tamaño, además de tiempos de creación. Se ha elaborado un gráfico (véase \ref{fig:BDD10_250}), tomando los valores de la tabla, que permite estimar el tiempo que tomaría crear fingerpirnts para 80.000 canciones, al extrapolar con una tendencia lineal. Es importante destacar que el valor 80.000 no es arbitrario, sino que corresponde a una aproximación realizada por la SCD sobre la actividad musical del país \cite{NumCanciones80k}.

Analizando la ecuación del gráfico se obtiene un tiempo de 279 días, por lo que se hace necesario modificar los atributos originales del programa para reducir el tiempo de creación de la base de datos oficial de la plataforma.

\paragraph{Análisis de atributos de configuración}
Según lo descrito en \ref{subsec:DescDejavu}, Dejavu cuenta con seis atributos que pueden ser modificado a la hora de crear la base de datos, por lo que cada uno de ellos fue analizado por separado, en bases de datos cuya cantidad de canciones variaban entre  3, 5 y 7.

La tabla del apéndice \ref{appendix:BDD3_5_7} contiene los valores de configuración de cada base de datos diseñada, con sus respectivos tiempos de creación y tamaños.

En base a éstas, se consideraron los siguientes factores para analizar el algoritmo, realizando pruebas de reconocimiento acústico:

\begin{itemize}
\item Tiempo de respuesta de Dejavu: indica el lapso que transcurre desde que el algoritmo recibe una consulta, crea los fingerpirnts del extracto de música analizado, y se buscan coincidencias en la base de datos, hasta que se devuelve la respuesta.

\item CONFIDENCIA: determina el porcentaje de confianza y veracidad de la respuesta entregada por el algoritmo.

\item Acierto: esta variable determina efectivamente si la salida del algoritmo corresponde al extracto de canción analizado.

\item Tamaño del extracto: elemento medido en segundos que determina la duración de cada archivo de música de prueba, abarcando un rango de 5, 10 y 15 segundos.

\item Sección del extracto: corresponde al momento en que se ha creado un extracto de música de prueba. De esta forma, se comprueba si el algoritmo acierta con la respuesta, independiente si la solicitud de reconocimiento acústico se hizo al principio, al final, o en la mitad de la canción. 
\end{itemize}

Para realizar las pruebas, se escogieron tres canciones arbitrarias que estaban presentes en todas las bases de datos diseñadas.

...

Adicionalmente se diseñaron algunos escenarios para comprobar un comportamiento adecuado del algoritmo, los que serán definidos a continuación.

\paragraph{Prueba de extractos de música no presente en la base de datos}

Un segundo ensayo consistió en evaluar los tiempos de ejecución del algoritmo de reconocimiento acústico, cuando los extractos de música no pertenecen a canciones que estén presentes en la base de datos.
 
Dado que la idea fundamental de esta plataforma es albergar solo la música chilena, se hizo este análisis con el propósito de determinar como sería mayoritariamente el comportamiento del algoritmo, debido a que, en general, la programación emitida por las radioemisoras nacionales es extranjera.

Los resultados señalan que ... 

\paragraph{Prueba de covers en Dejavu}

Es esperable que los fingerprints entre covers tengan cierta similitud, por lo que se ha escogido una serie de canciones para observar las respuestas del algoritmo. Inicialmente se escogieron canciones disponibles en la base de datos, y luego, se eliminaron algunas para comprobar si la respuesta de Dejavu sería o no el cover correspondiente.

Resultados...

\subsubsection{Configuración de Dejavu}
Entrecruzando toda la información de tablas y gráficos del presente capítulo, se ha optado por la siguiente configuración final de Dejavu, para el desarrollo de la plataforma:

[...]


\section{Descripción del Programa}

La siguiente etapa de este proyecto consiste en diseñar y desarrollar la plataforma de fiscalización, de tal forma que abarque solo la supervisión de una radio online. Por tanto, para abordar este requerimiento, se identificaron las tareas fundamentales del sistema para lograr su funcionamiento, las que se aprecian en el siguiente seudocódigo.


--Establecer valores de entrada
while (fin tiempo fiscalización)
	--Acceder a la url del streaming
	--Transformar señal continua de música en extractos discretos
	--Reconocer extracto con Dejavu
	--Exportar respuesta a documento de fiscalización
end

Cabe mencionar que la salida del programa corresponde a un archivo de texto que enlista el nombre de las canciones, con sus respectivos tiempos cronológicos de emisión.

La primera línea del código involucra determinar ciertos valores para la ejecución del programa, cuyo detalle se presenta a continuación:

\begin{itemize}
\item url: string que almacena el link del streaming de la radio que se controla.
\item delay: variable entera definida en segundos que indica cada cuanto tiempo se están creando extractos de música desde la radio, para transformar la señal continua en discreta, y hacer uso de Dejavu para su reconocimiento.

\item: fechaLimite: variable tipo fecha que puede ser definida de dos formas.

\begin{itemize}
\item fechaLimite en minutos: esta variable contabiliza el tiempo desde que se corre el programa hasta que transcurran los minutos definidos por el usuario.
\item fechaLimite como día: el programa se ejecuta hasta el día, hora, minutos y segundos, que se le definieron.
\end{itemize}

\item nombreRadio: variable que identifica por un nombre corto la radio que se analiza, y cuyo valor será utilizado para nombrar el archivo de salida.

\item segundosExtracto: variable entera que indica la duración que tendrán los extractos de música creados desde el streaming.

\end{itemize}

Para el ciclo iterativo se desarrolló una función llamada Repetir, la que se llama a sí misma cada cierto tiempo definido por la variable delay. Ésta, a su vez, llama a la función GenerarSplit, pero con un nuevo hilo de ejecución. De esta forma, independiente que el algoritmo tarde mucho en reconocer alguna canción, seguirán creándose extractos según los segundos definidos, sin necesidad de esperar la respuesta de Dejavu.

--Repetir(atributos)
--GenerarExtracto(atributos)

GenerarExtracto por su parte, corresponde a la función con más líneas de código, debido a que agrupa las tareas fundamentales. El próximo seudocódigo especifica su labor.

--Determinar nombre de archivo del extracto y fecha de creación
--while (time.time() - inicio < int(segundosExtracto*2))
	descargar segundos streaming
--cortar extracto 
[…]


Cabe destacar que el valor de la variable segundosDescarga es duplicado, debido a que la duración real de cada extracto varía en función de la memoria, tiempo de respuesta del servidor del streaming, etc, por lo que en ocasiones, estos archivos serán más cortos que el tiempo requerido.

[...]



